<!DOCTYPE html>
<html lang="en">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
		<title>Graph-based Text Representations</title>
		<meta name="ROBOTS" content="NOINDEX, NOFOLLOW">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<link href="./static/css/bootstrap.min.css" rel="stylesheet">
		<link href="./static/css/style.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="http://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
	</head>

	<body data-pinterest-extension-installed="cr1.40">
		<a name="home"></a>
		<nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
		  	<div class="container">
			    <!-- Brand and toggle get grouped for better mobile display -->
			    <div class="navbar-header">
					<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
				        <span class="sr-only">Toggle navigation</span>
				        <span class="icon-bar"></span>
				        <span class="icon-bar"></span>
				        <span class="icon-bar"></span>
			      	</button>
			      	<a class="navbar-brand" href="#home"><strong>EMNLP 2017 Tutorial</strong></a>
			    </div>

			    <!-- Collect the nav links, forms, and other content for toggling -->
			    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
			      	<ul class="nav navbar-nav navbar-right">
				        <li><a href="#overview"><span class="fa fa-bookmark-o"></span> Overview</a></li>
						<li><a href="#code"><span class="fa fa-file-pdf-o"></span> Slides</a></li>
						<li><a href="#people"><span class="fa fa-users"></span> Instructors</a></li>
			      	</ul>
			    </div><!-- /.navbar-collapse -->
		  </div><!-- /.container-fluid -->
		</nav>


		<div class="navblank">
		</div>

		<div class="title_box jumbotron">
			<div class="container">
				<h1>Graph-based Text Representations: <br> Boosting Text Mining, NLP and Information Retrieval with Graphs
				</h1>			
				<div class="description"></div>
			</div>
		</div>

		<div class="container">		
			<div class="content_box">
				<a name="overview"></a>
				<h2><span class="fa fa-bookmark-o"></span> Overview </h2>
				<blockquote class="text-justify"><p>Graphs or networks have been widely used as modeling tools in Natural Language Processing (NLP), Text Mining (TM) and Information Retrieval (IR). Traditionally, the unigram bag-of-words representation is applied; that way, a document is represented as a multiset of its terms, disregarding dependencies between the terms. Although several variants and extensions of this modeling approach have been proposed (e.g., the n-gram model), the main weakness comes from the underlying term independence assumption. The order of the terms within a document is completely disregarded and any relationship between terms is not taken into account in the final task (e.g., text categorization). Nevertheless, as the heterogeneity of text collections is increasing (especially with respect to document length and vocabulary), the research community has started exploring different document representations aiming to capture more fine-grained contexts of co-occurrence between different terms, challenging the well-established unigram bag-of-words model. To this direction, graphs constitute a well-developed model that has been adopted for text representation.  The goal of this tutorial is to offer a comprehensive presentation of recent methods that rely on graph-based text representations to deal with various tasks in NLP and IR. We will describe basic as well as novel graph theoretic concepts and we will examine how they can be applied in a wide range of text-related application domains. </p>
				</blockquote>
				<br>
				
				<div class="panel panel-default">
    				<div class="panel-body"><b>Graph-based Text Representations: Boosting Text Mining, NLP and Information Retrieval with Graphs.</b><br> Fragkiskos D. Malliaros and Michalis Vazirgiannis. <br> 
    				<i>Conference on Empirical Methods in Natural Language Processing (<b>EMNLP</b>) </i>, Copenhagen, Denmark, 2017. (To Appear). </div>
  				</div>
				


				<br><br><br>
				<a name="code"></a>
				<h2><span class="fa fa-file-pdf-o"></span> Slides </h2>
				
				TBA

				<!--
				<span id="emp"></span> <a href="http://fragkiskosm.github.io/papers/Tutorial_Slides_ICDM_2016.pdf"> Tutorial_Slides</a><br> <br> <br> --><br>
				
				


				<br><br>
				<div >
					<a name="people"></a>
					<h2><span class="fa fa-users"></span> Instructors</h2>
					<ul>
						<li> 
							<a href="http://fragkiskos.me">Fragkiskos D. Malliaros</a> (UC San Diego)
						</li>					
						<li> 
							<a href="http://www.lix.polytechnique.fr/~mvazirg/">Michalis Vazirgiannis</a> (&Eacute;cole Polytechnique)
						</li>
					</ul>
				</div>
			</div>	
		</div>
		<div class="navblank"></div>
		<div class="navblank"></div>
		<footer></footer>

		<script type="text/javascript" src="./static/js/jquery-1.10.2.min.js"></script>
		<script type="text/javascript" src="./static/js/bootstrap.min.js"></script>
		
	</body>
</html>